## План работы
### Первый этап (чекпоинт 2). Данные и EDA.

#### План:
На этом этапе:
1. Знакомимся с темой, читаем статьи, смотрим, какие есть подходы к решению подобных задач. 
2. Ищем подходящий датасет, изучаем его. При необходимости собираем свои данные.
3. Проводим анализ датасета (размеры, выбросы, качество данных и т.п.). При необходимости выбираем подходящие аугментации.
4. Изучаем существующие метрики для оценки изображений. выбираем подходящие нам.

На данный момент нашли 2 статьи, где решается похожая задача:

https://arxiv.org/abs/2404.16022

https://arxiv.org/pdf/2312.04461

#### Результаты:

- Нашли датасет [Multi-Modal-CelebA-HQ](https://github.com/IIGROUP/MM-CelebA-HQ-Dataset) (подробнее в dataset.md)
- Провели анализ данных (см. общее описание в EDA.md)

### Второй этап (чекпоинт 3). Baseline

Для начала пытаемся использовать более простые подходы. Текущая идея: обучить ip adapter на stable diffusion с control net

#### Построение бейзлайна. Результаты.

В качестве бейзлайна мы обучили  ip-adapter на stable-diffusion-v1.5.

- Подробности в файле baseline.md
- Пример обучения и применения модели в файле ip_adapter_demo.ipynb
- Скрипт с подсчетом метрик в ip_adapter_metrics.ipynb

### Третий этап. DL

Пробуем что-то более интересное. Имплементим решение из релевантной статьи или пробуем собрать что-то свое похожее.

### Четвертый этап. Сервис (TG bot)

Делаем бота, который будет предоставлять доступ к нашей итоговой модели. Например, принимать фото/текстовое описание и возвращать аниме-картинку.

## Распределение задач:

Задачи распределяем отдельно под каждый из этапов. Стараемся эффективно организовать написание кода и тестирование моделей, чтобы все вместе занимало меньше времени.
